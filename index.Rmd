---
title: "Team Beta Final Project"
author: "Alper Sukru Gencer,  Gechun Lin,  William Loh"
output: html_document
runtime: shiny
---

<center>
![{***COVID-19: Novel Coronavirus***}](https://www.co.monterey.ca.us/Home/ShowPublishedImage/26051/637174704567470000)
</center>

## I. Introduction

#### The Covid-19 outbreak has changed every aspect of daily life, which can be seen in the substantial shifts in the way people search certain terms on internet. Our final project is to create a Shiny App that allows the users to analyze how interest in certain search terms have changed vis-a-vis the Covid-19 lockdown based on Google Search Trends Data.

#### Let's start! 

#### Please type <span style="color: red;">**any search term**</span>  you are in interested. And do not forget to specify the <span style="color: red;">**state**</span>!

## II. COVID-19 Search Trends 


```{r getting ready, echo= F, include=FALSE}
####  Clear All
rm(list = ls())
####  Libraries
library(shiny)
library(gtrendsR)
library(tidyverse)
library(dplyr)
```

```{r function, include = FALSE, warning = FALSE, message = FALSE}
  ##Output
  #---  Categories dataset composed of exisiting research categories (not vital)
  #data("categories")
  #str(categories)
  
  #---  Getting Data on State Abbreviations
  #data('state')
  statecodes <- read.csv("https://raw.githubusercontent.com/williamloh1/teambeta/master/Project/datasets/state%20codes.csv")
  state.df <- as.data.frame(cbind(state.x77, state.abb, state.area, state.division, state.name, state.region))

  #---  Creating a function that takes three arguments
  #---    1)  a string vector of keywords     (default: covid19)
  #---    2)  a state abbreviation            (default: whole US)
  #---    2)  a boolean of percentage change  (default: FALSE)
  my.fun <- function(vector.keyword = "covid19",  state.abbr = "US", change = FALSE){
    library(gtrendsR)
    library(tidyverse)
    library(dplyr)
    result <- gtrends(keyword = vector.keyword, geo = as.character(state.abbr), time = "2020-03-01 2020-04-15",
                      gprop = c("web"),
                      category = 0, hl = "en-US", low_search_volume = FALSE,
                      cookie_url = "http://trends.google.com/Cookies/NID", tz = 0,
                      onlyInterest = T)
    result <- as.data.frame(result[1]) %>%
      mutate(interest_over_time.hits.change = interest_over_time.hits - lag(interest_over_time.hits))
    lockdown <- read.csv("https://raw.githubusercontent.com/williamloh1/teambeta/master/Project/datasets/lockdown_dates.csv")
    USlockdown <- lockdown[which(lockdown$Country=="United States"), ]
    USlockdown$Place <- state.abb[match(USlockdown$Place, state.name)]
    USlockdown$Place <- paste0("US-", USlockdown$Place)
    
    if(change == FALSE){if(is.element(state.abbr, USlockdown$Place)==T){
      statelock <- USlockdown[USlockdown$Place==state.abbr, ]
      ggplot(result, aes(x=as.Date(interest_over_time.date), y=interest_over_time.hits)) +
        geom_line( color="#69b3a2") + 
        ylab("Hits") +
        ggtitle(paste0("Search trend of ", vector.keyword, " over time in ", state.abbr)) +
        xlab("") + 
        ylim(0,100) +
        theme_light() +
        theme(axis.text.x=element_text(angle=60, hjust=1))+
        geom_vline(xintercept = as.Date(statelock$Start.date))+
        geom_text(aes(x=as.Date(statelock$Start.date), label="\nafter lockdown", y=mean(range(interest_over_time.hits))), size=4, colour="grey", angle=90) +
        geom_text(aes(x=as.Date(statelock$Start.date), label="before lockdown\n", y=mean(range(interest_over_time.hits))), size=4, colour="grey", angle=90)
    } else{ggplot(result, aes(x=as.Date(interest_over_time.date), y=interest_over_time.hits)) +
        geom_line( color="#69b3a2") + 
        ylab("Hits") +
        ggtitle(paste0("Search trend of ", vector.keyword, " over time in ", state.abbr)) +
        xlab("") + 
        ylim(0,100) +
        theme_light() +
        theme(axis.text.x=element_text(angle=60, hjust=1))}
    } else {if(is.element(state.abbr, USlockdown$Place)==T){
      statelock <- USlockdown[USlockdown$Place==state.abbr, ]
      ggplot(result, aes(x=as.Date(interest_over_time.date), y=interest_over_time.hits.change)) +
        geom_line( color="#69b3a2") + 
        ylab("Change in Hits") +
        ggtitle(paste0("Change of search trend of ", vector.keyword, " over time in ", state.abbr)) +
        xlab("") +
        theme_light() +
        theme(axis.text.x=element_text(angle=60, hjust=1))+
        geom_vline(xintercept = as.Date(statelock$Start.date))+
        geom_text(aes(x=as.Date(statelock$Start.date), label="\nafter lockdown", y=mean(range(interest_over_time.hits.change[-1]))), size=4, colour="grey", angle=90) +
        geom_text(aes(x=as.Date(statelock$Start.date), label="before lockdown\n", y=mean(range(interest_over_time.hits.change[-1]))), size=4, colour="grey", angle=90)
    } else{
      ggplot(result, aes(x=as.Date(interest_over_time.date), y=interest_over_time.hits.change)) +
        geom_line( color="#69b3a2") + 
        ylab("Change in Hits") +
        ggtitle(paste0("Change of search trend of ", vector.keyword, " over time in ", state.abbr)) +
        xlab("") +
        theme_light() +
        theme(axis.text.x=element_text(angle=60, hjust=1))
    }
    }
  }
```




<center>
```{r shiny, echo=FALSE}
statecodes <- read.csv("https://raw.githubusercontent.com/williamloh1/teambeta/master/Project/datasets/state%20codes.csv")
shinyApp(
  ui = fluidPage(
    sidebarLayout( ## Choosing layout with inputs on side and 
      ## outputs displayed in the main body
      sidebarPanel( #Things in this function specify the sidebar
        selectInput(label = "State: ",
                    choices = statecodes$state, inputId = "stateterm"),
        textInput(inputId = "searchterm", 
                  label = "Search Term:",
                  value="covid"
        ), 
        selectInput(label = "Type of query: ",
                    choices = c("Hits per Day","Day-to-day change in hits"),
                    inputId = "querytype")),
        ## End of sidebar
      mainPanel( ## Arguments for main section (output)
        plotOutput("searchGraph")
      ) # Close main panel
    )
  ),
  server = function(input, output){
  output$searchGraph <- renderPlot({
      statecodes <- read.csv("https://raw.githubusercontent.com/williamloh1/teambeta/master/Project/datasets/state%20codes.csv")
      state.code <- statecodes$state_code[statecodes$state == input$stateterm]
      bool <- T
      if (input$querytype == "Hits per Day") {
        bool <- F
      }
      graph.output <- my.fun(vector.keyword = input$searchterm, state.abbr = paste0("US-", state.code), bool)
      print(graph.output)
    })
  },
  options = list(height = 500)
)
```
</center>


## III. The Shiny App: What do I see here? 


#### - **The Shiny App**:
  - **What it does**: The app allows the user to input different search terms and outputs different visualizations to show how the popularity of that term has changed during quarantine. 
  - **Visualizations**
    - Hits-per-day: Displays a line graph showing the popularity of the term through time. The y-axis is similar to "hits" per day, but in relative terms. In other words, based on how many hits the term generated compared to the rest of the time frame, it will receive a score from 1-100. The x-axis is days in the past 45 day time frame (current frame is set from March 1 to April 15). 
    - Day-to-day change in hits: Displays a line graph showing the derivative of the hits-per-day graph. In other words, it takes the delta between two consecutive dates and plots it. So, the y-axis is "Change in Hits" and the x-axis is days again.


#### - **Components of the App**:

  - **Google Search Trends Data**: Google Trends provides access to a largely unfiltered sample of actual anonymized and aggregated search requests made to Google. This allows us to display interest in a particular topic from around the globe or down to city-level geography. The sample that the Google Trends draws on millions of search attempts that are mostly representative for all searches on Google. Note that the Google Trends normalizes search data to make comparisons between terms and geographies easier. Search results are normalized to the time and location of a query by being sorted by the total searches of the geography and time range it represents to compare relative popularity. Otherwise, places with the most search volume would always be ranked highest. The resulting numbers are then scaled on a range of 0 to 100 based on a topic’s proportion to all searches on all topics. Different regions that show the same search interest for a term don't always have the same total search volumes. For further information see the associated, please [documentation](https://support.google.com/trends/answer/4365533?hl=en).
  
  - **‘gtrendsR’**: In obtaining the Google Trends Data, our App makes use of an api called *‘gtrendsR’*. The *‘gtrendsR’* allows us to retrive the *Google Trends* data, the normalized trend of terms, by specifying certain 1) search terms, 2) units of geographies, and 3) time ranges. Because we want the users to search for any term that they are interested, we did not specify a certain search term. Instead, the *‘gtrendsR’* retrives whatever the user desires to see. As we are interested with the search trends in the US, we also use the *‘gtrendsR’* to call only the states in the United States. This specification any possible mistakes in the locality searches (e.g. Canada (CA) vs California (US-CA)). Lastly, because we are only interested in the search term trends given the covid-19, we specify the time range between March 01 2020 and April 15 2020. This allows us to see the results that are normalized based on Covid-19 crisis. For further information, please see the related [documentation](https://cran.r-project.org/web/packages/gtrendsR/gtrendsR.pdf).
  
  - **The Lockdown Dataset**: [Aura Vision](https://auravision.ai/covid19-lockdown-tracker/) provides a Global Covid-19 Lockdown Tracker which source data is downloadable. The [dataset](https://raw.githubusercontent.com/williamloh1/teambeta/master/Project/datasets/lockdown_dates.csv) includes the start date and end date of lockdowns at different places as well as their information source. Based on the lockdown dataset, we draw a vertical line at x=Start Date of Lockdown in the plot if that state has started lockdown during March 01 2020 and April 15 2020. We believe that no US state ends lockdown before April 15 2020.   
 

#### - **The Website**:

  - We built this website using the principles we learned in **Lecture 25**. Our process started with developing the data collection (datasets with information on lockdown dates by states) and parsing to gather the right visualizations. 
  - Then, we transformed it into a **`Shiny App'**, which collected user input and fed it into our algorithm. 
  - Next, we converted our Shiny app into a **R markdown file**, which was easily converted into a website. 
  - Finally, to have a server for our dynamic website, we use the **`shinyapps.io'**, which offers free servers for Shiny-embedded .Rmd file. For further information, please see the related [website](https://www.shinyapps.io/).


## IV. Example Search Terms Analyses 

<center>
![{***COVID-19: Novel Coronavirus***}](https://media.canadianunderwriter.ca/uploads/2020/04/COVID-19-economy.jpg)
</center>

#### Here we analyze the changes in five search clusters, which contain popular terms, waning terms, lockdown-sensitive terms, lockdown-insensitive terms, and partisan terms. In doing so, we show how results vary based on the state of interest. We pick six states with different partisan support, which are <span style="color: blue;">Blue</span> (New York and California),  <span style="color: grey;">Competitive</span> (Florida and Minnesota), and  <span style="color: red;">Red</span> (Texas and Georgia), to see if the search trend patterns of some terms differ across states! 


```{r getting ready 2, echo= F, include=F}
library(gridExtra)
my.list <- as.list(NULL)
my.states <- c("NY", "CA", "TX", "GA", "FL", "MN")
my.fun2 <- function(vector.keyword = "covid19",  state.abbr = "US", change = FALSE){
    library(gtrendsR)
    library(tidyverse)
    library(dplyr)
    result <- gtrends(keyword = vector.keyword, geo = as.character(state.abbr), time = "2020-03-01 2020-04-15",
                      gprop = c("web"),
                      category = 0, hl = "en-US", low_search_volume = FALSE,
                      cookie_url = "http://trends.google.com/Cookies/NID", tz = 0,
                      onlyInterest = T)
    result <- as.data.frame(result[1]) %>%
      mutate(interest_over_time.hits.change = interest_over_time.hits - lag(interest_over_time.hits))
    lockdown <- read.csv("https://raw.githubusercontent.com/williamloh1/teambeta/master/Project/datasets/lockdown_dates.csv")
    USlockdown <- lockdown[which(lockdown$Country=="United States"), ]
    USlockdown$Place <- state.abb[match(USlockdown$Place, state.name)]
    USlockdown$Place <- paste0("US-", USlockdown$Place)
    
    if(change == FALSE){if(is.element(state.abbr, USlockdown$Place)==T){
      statelock <- USlockdown[USlockdown$Place==state.abbr, ]
      ggplot(result, aes(x=as.Date(interest_over_time.date), y=interest_over_time.hits)) +
        geom_line( color="#69b3a2") + 
        ylab("Hits") +
        ggtitle(paste0("Search trend in ", state.abbr)) +
        xlab("") + 
        ylim(0,100) +
        theme_light() +
        theme(axis.text.x=element_text(angle=60, hjust=1))+
        geom_vline(xintercept = as.Date(statelock$Start.date))+
        geom_text(aes(x=as.Date(statelock$Start.date), label="\nafter lockdown", y=mean(range(interest_over_time.hits))), size=2, colour="grey", angle=90) +
        geom_text(aes(x=as.Date(statelock$Start.date), label="before lockdown\n", y=mean(range(interest_over_time.hits))), size=2, colour="grey", angle=90)
    } else{ggplot(result, aes(x=as.Date(interest_over_time.date), y=interest_over_time.hits)) +
        geom_line( color="#69b3a2") + 
        ylab("Hits") +
        ggtitle(paste0("Search trend in ", state.abbr)) +
        xlab("") + 
        ylim(0,100) +
        theme_light() +
        theme(axis.text.x=element_text(angle=60, hjust=1))}
    } else {if(is.element(state.abbr, USlockdown$Place)==T){
      statelock <- USlockdown[USlockdown$Place==state.abbr, ]
      ggplot(result, aes(x=as.Date(interest_over_time.date), y=interest_over_time.hits.change)) +
        geom_line( color="#69b3a2") + 
        ylab("Change in Hits") +
        ggtitle(paste0("Search trend in ", state.abbr)) +
        xlab("") +
        theme_light() +
        theme(axis.text.x=element_text(angle=60, hjust=1))+
        geom_vline(xintercept = as.Date(statelock$Start.date))+
        geom_text(aes(x=as.Date(statelock$Start.date), label="\nafter lockdown", y=mean(range(interest_over_time.hits.change[-1]))), size=2, colour="grey", angle=90) +
        geom_text(aes(x=as.Date(statelock$Start.date), label="before lockdown\n", y=mean(range(interest_over_time.hits.change[-1]))), size=2, colour="grey", angle=90)
    } else{
      ggplot(result, aes(x=as.Date(interest_over_time.date), y=interest_over_time.hits.change)) +
        geom_line( color="#69b3a2") + 
        ylab("Change in Hits") +
        ggtitle(paste0("Search trend in ", state.abbr)) +
        xlab("") +
        theme_light() +
        theme(axis.text.x=element_text(angle=60, hjust=1))
    }
    }
}
```

$~$

$~$

### Search Cluster 1: Popular Terms After Lockdowns 

```{r Nintendo Switch, echo= F, warning=F, include=T,  fig.align = "center", fig.cap = "The Search Trend of Nintendo Switch Across States"}
for(i in 1:6){
  assign(paste0(my.states[i]), my.fun2(vector.keyword = "Nintendo Switch", state.abbr = paste0("US-", my.states[i])))
}
grid.arrange(NY, CA, FL, MN, TX, GA)
```

#### As the plots show, the search terms, **Nintendo Switch**, **Sourdough**, and **Unemployment** have become increasing popular since the the first wave of lockdowns in mid-March 20. 

```{r Sourdough, echo= F, include=T,  warning=F, fig.align = "center", fig.cap = "The Search Trend of Sourdough Across States"}
for(i in 1:6){
  assign(paste0(my.states[i]), my.fun2(vector.keyword = "sourdough", state.abbr = paste0("US-", my.states[i])))
}
grid.arrange(NY, CA, FL, MN, TX, GA)
```

#### These search trends reflect self-quarantine behavior. Note that people who had to stay at home after the lockdown are in the search of new self-oocupations. The popular attention has shifted to home entertainment, such as **Nintendo Switch** and **Sourdough**. 

```{r Unemploment, echo= F, include=T, warning=F,  fig.align = "center", fig.cap = "The Search Trend of Unemployment Across States"}
for(i in 1:6){
  assign(paste0(my.states[i]), my.fun2(vector.keyword = "unemployment", state.abbr = paste0("US-", my.states[i])))
}
grid.arrange(NY, CA, FL, MN, TX, GA)
```

####  Because lockdowns and the following economic recession caused anxiety over unemployment, it can be seen that **Unemployment** has been increasingly searched in after lockdowns. Note that the partisanship across states does not seem to reflect huge effect on how people are concerned with self-occupation.  

$~$

$~$

$~$

### Search Cluster 2: Waning Terms After Lockdowns 

```{r Cheap Tickets, echo= F, include=T, warning=F,  fig.align = "center", fig.cap = "The Search Trend of Cheap Tickets Across States"}
for(i in 1:6){
  assign(paste0(my.states[i]), my.fun2(vector.keyword = "cheap tickets", state.abbr = paste0("US-", my.states[i])))
}
grid.arrange(NY, CA, FL, MN, TX, GA)
```

#### In contrast to the previous cluster of terms, terms like **Cheap Tickets** and **Basketball** are on the wane.

```{r basketball, echo= F, include=T, warning=F,  fig.align = "center", fig.cap = "The Search Trend of Basketball Across States"}
for(i in 1:6){
  assign(paste0(my.states[i]), my.fun2(vector.keyword = "Basketball", state.abbr = paste0("US-", my.states[i])))
}
grid.arrange(NY, CA, FL, MN, TX, GA)
```

#### After the lockdown, international and domestic travel are seriously restricted, which is probably the reason why people search cheap tickets less than before. Also the NBA has announced its decision to suspend season on March 12. So, the search trend of basketball is down since then. Again, we do not observe any different search trend patterns across states. 


$~$

$~$

$~$

### Search Cluster 3: Lockdown-Sensitive Terms 

```{r businesses, echo= F, include=T, warning=F,  fig.align = "center", fig.cap = "The Search Trend of Businesses Across States"}
for(i in 1:6){
  assign(paste0(my.states[i]), my.fun2(vector.keyword = "businesses", state.abbr = paste0("US-", my.states[i])))
}
grid.arrange(NY, CA, FL, MN, TX, GA)
```

#### See that some terms are very sensitive to lockdown. For example, **Businesses** search spiked around the start date of lockdown in each state (except Texas). 

$~$

$~$

$~$

### Search Cluster 4: Lockdown-Insensitive Terms 

```{r Mask, echo= F, include=T, warning=F,  fig.align = "center", fig.cap = "The Search Trend of Face Mask Across States"}
for(i in 1:6){
  assign(paste0(my.states[i]), my.fun2(vector.keyword = "face mask", state.abbr = paste0("US-", my.states[i])))
}
grid.arrange(NY, CA, FL, MN, TX, GA)
```

#### Nevertheless, other terms such as **"face mask"** are less affected by the lockdown. In fact, see that people searched for **face masks** relatively less often until the CDC suggested people to wear them for protection at the begining of April 2020. 

$~$

$~$

$~$

### Search Cluster 5: Partisan Terms

```{r Protests, echo= F, include=T, warning=F,  fig.align = "center", fig.cap = "The Search Trend of Protest Across States"}
for(i in 1:6){
  assign(paste0(my.states[i]), my.fun2(vector.keyword = "Protests", state.abbr = paste0("US-", my.states[i])))
}
grid.arrange(NY, CA, FL, MN, TX, GA)
```

#### What about the highly-partisan search terms?

```{r First, echo= F, include=T, warning=F,  fig.align = "center", fig.cap = "The Search Trend of First Amendment Across States"}
for(i in 1:6){
  assign(paste0(my.states[i]), my.fun2(vector.keyword = "First Amendment", state.abbr = paste0("US-", my.states[i])))
}
grid.arrange(NY, CA, FL, MN, TX, GA)
```

#### It turns out that polorized search terms, including **protest**, **first amendment**, **firearms**, do not reflect particularly distinct patterns across states with partisan ideology. 

```{r Firearms, echo= F, include=T, warning=F,  fig.align = "center", fig.cap = "The Search Trend of Firearms Across States"}
for(i in 1:6){
  assign(paste0(my.states[i]), my.fun2(vector.keyword = "Firearms", state.abbr = paste0("US-", my.states[i])))
}
grid.arrange(NY, CA, FL, MN, TX, GA)
```

####  See that it is hard to find a **descriptive** association between partsianship and search trend. So, we suggest that though there maybe individual level partisan differences, these are hard to detect at state level based on partisan support.


$~$

